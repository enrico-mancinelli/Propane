{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import metpy\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.units import units\n",
    "from metpy.calc import dewpoint_from_relative_humidity\n",
    "from metpy.calc import specific_humidity_from_dewpoint\n",
    "from pint import UnitRegistry\n",
    "ureg = UnitRegistry()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract epoch from the first few rows of the CSV file\n",
    "def extract_epoch_from_header(file):\n",
    "    # Read the first few lines to find the epoch (assuming it's in a comment or a header)\n",
    "    with open(file, 'r') as f:\n",
    "        skiprow = f.readline()\n",
    "        skiprow = skiprow.strip().split()[0]\n",
    "        for line in f:\n",
    "            if \"startdate:\" in line.lower():  # Assuming the word 'epoch' is present in the line\n",
    "                # Extract the epoch date (this assumes the date is the second item in the line)\n",
    "                epoch = line.strip().split()[1]\n",
    "                return int(skiprow)-1, epoch[0:4]+\"-\"+epoch[4:6]+\"-\"+epoch[6:8]+\" \"+epoch[8:10]+\":\"+epoch[10:12]+\":\"+epoch[12:14]\n",
    "    return None  # Return None if no epoch is found\n",
    "\n",
    "# Function to load and adjust time for each CSV\n",
    "def load_and_adjust_time(file):\n",
    "    # Try to extract the epoch from the header or a specific column\n",
    "    nskiprows,epoch = extract_epoch_from_header(file)\n",
    "   \n",
    "    if epoch is None:\n",
    "        raise ValueError(f\"Could not find epoch for file: {file}\")\n",
    "   \n",
    "    # Load the actual data (skipping header if necessary)\n",
    "    df = pd.read_csv(file, skiprows=nskiprows,sep=\"\\\\s+\")  # Adjust skiprows based on where the data starts\n",
    "   \n",
    "    # Convert 'time' column to a datetime, assuming it's in days\n",
    "    # Adjust time column to start from the epoch time found in the file\n",
    "    df['starttime_dt'] = pd.to_timedelta(df['starttime'], unit='D') + pd.Timestamp(epoch)\n",
    "    #df = df[df.flag_rH != 0.999]\n",
    "    #df.index = df[\"starttime_dt\"]\n",
    "    #data[\"starttime_dt\"] = pd.to_datetime(data[\"starttime\"],unit='D',origin=pd.Timestamp('2015-01-01 00:41:00'))\n",
    "   \n",
    "    # Return the adjusted DataFrame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set a working directory till NMVOC folder\n",
    "working_dir = \"C:\\\\Year1\\\\\"\n",
    "# Find all CSV files (change the path if nedeed)\n",
    "rh_files = glob.glob(working_dir+\"NMVOC\\\\Meteo_ebas_CMN\\\\Ebas_240920_1134\\\\*.nas\")\n",
    "print(rh_files)\n",
    "\n",
    "# this function reads and adjust times for all CSV files\n",
    "dfs = []\n",
    "for file in rh_files:\n",
    "    df = load_and_adjust_time(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# concatenates all DataFrames (based on time)\n",
    "rh_df = pd.concat(dfs).sort_values('starttime_dt').reset_index(drop=True)\n",
    "\n",
    "# Show combined DataFrame\n",
    "print(rh_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract epoch from the first few rows of the CSV file\n",
    "def extract_epoch_from_header(file):\n",
    "    # Read the first few lines to find the epoch (assuming it's in a comment or a header)\n",
    "    with open(file, 'r') as f:\n",
    "        skiprow = f.readline()\n",
    "        skiprow = skiprow.strip().split()[0]\n",
    "        for line in f:\n",
    "            if \"startdate:\" in line.lower():  # Assuming the word 'epoch' is present in the line\n",
    "                # Extract the epoch date (this assumes the date is the second item in the line)\n",
    "                epoch = line.strip().split()[1]\n",
    "                return int(skiprow)-1, epoch[0:4]+\"-\"+epoch[4:6]+\"-\"+epoch[6:8]+\" \"+epoch[8:10]+\":\"+epoch[10:12]+\":\"+epoch[12:14]\n",
    "    return None  # Return None if no epoch is found\n",
    "\n",
    "# Function to load and adjust time for each CSV\n",
    "def load_and_adjust_time(file):\n",
    "    # Try to extract the epoch from the header or a specific column\n",
    "    nskiprows,epoch = extract_epoch_from_header(file)\n",
    "   \n",
    "    if epoch is None:\n",
    "        raise ValueError(f\"Could not find epoch for file: {file}\")\n",
    "   \n",
    "    # Load the actual data (skipping header if necessary)\n",
    "    df = pd.read_csv(file, skiprows=nskiprows,sep=\"\\\\s+\")  # Adjust skiprows based on where the data starts\n",
    "   \n",
    "    # Convert 'time' column to a datetime, assuming it's in days\n",
    "    # Adjust time column to start from the epoch time found in the file\n",
    "    df['starttime_dt'] = pd.to_timedelta(df['starttime'], unit='D') + pd.Timestamp(epoch)\n",
    "   \n",
    "    # Return the adjusted DataFrame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set a working directory till NMVOC folder\n",
    "working_dir = \"C:\\\\Year1\\\\\"\n",
    "# Find all CSV files (change the path if nedded)\n",
    "temperature_files = glob.glob(working_dir+\"NMVOC\\\\Meteo_ebas_CMN\\\\Ebas_240920_1140\\\\*.nas\")\n",
    "print(temperature_files)\n",
    "\n",
    "# this function reads and adjust times for all CSV files\n",
    "dfs = []\n",
    "for file in temperature_files:\n",
    "    df = load_and_adjust_time(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# concatenates all DataFrames (based on time)\n",
    "temperature_df = pd.concat(dfs).sort_values('starttime_dt').reset_index(drop=True)\n",
    "\n",
    "# Show combined DataFrame\n",
    "print(temperature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set a working directory till NMVOC folder\n",
    "working_dir = \"C:\\\\Year1\\\\\"\n",
    "# Find all CSV files (change the path if nedded)\n",
    "temperature_files = glob.glob(working_dir+\"NMVOC\\\\Meteo_ebas_CMN\\\\Ebas_240923_1438\\\\*.nas\")\n",
    "print(temperature_files)\n",
    "\n",
    "# this function reads and adjust times for all CSV files\n",
    "dfs = []\n",
    "for file in temperature_files:\n",
    "    df = load_and_adjust_time(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# concatenates all DataFrames (based on time)\n",
    "p_df = pd.concat(dfs).sort_values('starttime_dt').reset_index(drop=True)\n",
    "\n",
    "# Show combined DataFrame\n",
    "print(p_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove lines depending on flags\n",
    "df=temperature_df\n",
    "df [\"RH\"] = rh_df.rH\n",
    "df [\"flag_RH\"] = rh_df.flag_rH\n",
    "df [\"flag_P\"] = p_df.flag_P\n",
    "df [\"P\"] = p_df.P\n",
    "df = df[df.flag_T != 0.999]\n",
    "df = df[df.flag_RH != 0.999]\n",
    "df = df[df.flag_P != 0.999]\n",
    "df = df[df.flag_T != 0.899]\n",
    "df = df[df.flag_RH != 0.899]\n",
    "df = df[df.flag_P != 0.899]\n",
    "df = df[df.flag_T != 0.260]\n",
    "df = df[df.flag_RH != 0.260]\n",
    "df = df[df.flag_P != 0.260]\n",
    "df = df[df.flag_T != 0.259]\n",
    "df = df[df.flag_RH != 0.259]\n",
    "df = df[df.flag_P != 0.259]\n",
    "df = df[df.flag_T != 0.256]\n",
    "df = df[df.flag_RH != 0.256]\n",
    "df = df[df.flag_P != 0.256]\n",
    "df.index = df[\"starttime_dt\"]\n",
    "#remove useless columns\n",
    "df = df.drop(columns=[\"flag_P\"])\n",
    "df = df.drop(columns=[\"flag_RH\"])\n",
    "df = df.drop(columns=[\"flag_T\"])\n",
    "df = df.drop(columns=[\"starttime\"])\n",
    "df = df.drop(columns=[\"endtime\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop for rounding to the hours\n",
    "df[\"starttime_dt\"] = [i.round(\"H\") for i in df[\"starttime_dt\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper columns with  hour, month, year\n",
    "df['hour'] = df['starttime_dt'].dt.hour\n",
    "df['month'] = df['starttime_dt'].dt.month\n",
    "df['year'] = df['starttime_dt'].dt.year\n",
    "df['date'] = df['starttime_dt'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dewpoint from T and RH\n",
    "dewpoint=dewpoint_from_relative_humidity(df[\"T\"].values*units.degC, df[\"RH\"].values*units.percent)\n",
    "dewpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specific humidity from temperature and dewpoint\n",
    "SH=specific_humidity_from_dewpoint(df[\"P\"].values*units.hPa, dewpoint).to('g/kg')\n",
    "df [\"SH\"] = SH\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate monthly mean, 'min', 'max', 'std', 'count' of SH\n",
    "df['month'] = df['starttime_dt'].dt.month\n",
    "SH_mean_hour=(df.groupby(['month']).agg({'SH': ['mean','min', 'max', 'std', 'count'] }))\n",
    "SH_mean_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate monthly means each year\n",
    "df.groupby([df[\"starttime_dt\"].dt.year, \"month\"])[\"SH\"].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot hourly mean\n",
    "df.groupby(df[\"starttime_dt\"].dt.hour)[\"SH\"].mean().plot(marker=\"o\",linewidth=0)\n",
    "\n",
    "plt.xlabel(\"Time, hour\");  # custom x label using Matplotlib\n",
    "\n",
    "plt.ylabel(\"$Specific humidity (g/kg)$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date column to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Function to determine season\n",
    "def get_season(date):\n",
    "    month = date.month\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    else:\n",
    "        return 'Fall'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#season\n",
    "seasons = [1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 1]\n",
    "month_to_season = dict(zip(range(1,13), seasons))\n",
    "month_to_season \n",
    "S=df.starttime_dt.dt.month.map(month_to_season) \n",
    "df['season']=S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#means per season each year \n",
    "df.groupby(['year', 'season']).agg({'SH': ['mean','min', 'max', 'std', 'count']})\n",
    "plot = df.groupby(['year', 'season']).agg({'SH': ['mean']}).plot(title=\"Seasonal mean specific humidity\")#,marker=\"o\",linewidth=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Extract year and season\n",
    "df['year'] = df['date'].dt.year\n",
    "df['season'] = df['date'].apply(get_season)\n",
    "\n",
    "# Group by year and season and calculate mean value (or sum, etc.)\n",
    "grouped = df.groupby(['season', 'year'])['SH'].mean().unstack()\n",
    "\n",
    "# Reorder the seasons\n",
    "season_order = ['Winter', 'Spring', 'Summer', 'Fall']\n",
    "grouped = grouped.reindex(season_order)\n",
    "\n",
    "# Plot for different years\n",
    "grouped.plot(kind='line', marker='o', figsize=(10, 6))\n",
    "\n",
    "# Customize plot\n",
    "plt.title('Value by Season for Different Years')\n",
    "plt.ylabel('SH [g/kg]')\n",
    "plt.xlabel('Season')\n",
    "plt.xticks(range(len(season_order)), season_order)\n",
    "plt.legend(title='Year')\n",
    "plt.grid(True)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
