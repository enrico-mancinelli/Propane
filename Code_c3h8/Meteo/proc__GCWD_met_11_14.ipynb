{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import metpy\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.units import units\n",
    "from metpy.calc import dewpoint_from_relative_humidity\n",
    "from metpy.calc import specific_humidity_from_dewpoint\n",
    "from pint import UnitRegistry\n",
    "ureg = UnitRegistry()\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Year1\\NMVOC\\Data\\data_Meteo\\Meteo_ebas_11_15\\cmn644n00.isac.xx.xx.met.nl.ev2011.dat\n",
      "Processing file: C:\\Year1\\NMVOC\\Data\\data_Meteo\\Meteo_ebas_11_15\\cmn644n00.isac.xx.xx.met.nl.ev2012.dat\n",
      "Processing file: C:\\Year1\\NMVOC\\Data\\data_Meteo\\Meteo_ebas_11_15\\cmn644n00.isac.xx.xx.met.nl.ev2013.dat\n",
      "Processing file: C:\\Year1\\NMVOC\\Data\\data_Meteo\\Meteo_ebas_11_15\\cmn644n00.isac.xx.xx.met.nl.ev2014.dat\n",
      "Saved final concatenated data to: C:\\Year1\\NMVOC\\Data\\data_Meteo\\processed_met_11_14.csv\n",
      "Processing complete for all .dat files.\n",
      "                     wind_speed  temperature  relative_humidity  pressure\n",
      "DATETIME                                                                 \n",
      "2011-01-18 12:00:00        6.50         4.40              33.65    793.95\n",
      "2011-01-18 13:00:00        7.45         4.45              33.60    793.45\n",
      "2011-01-18 14:00:00        7.25         4.55              32.10    793.10\n",
      "2011-01-18 15:00:00        7.65         4.25              33.40    793.00\n",
      "2011-01-18 16:00:00        8.70         3.50              32.45    793.05\n",
      "...                         ...          ...                ...       ...\n",
      "2014-12-31 19:00:00       36.00       -15.00              82.40    786.20\n",
      "2014-12-31 20:00:00       36.00       -15.40              82.50    787.90\n",
      "2014-12-31 21:00:00       35.00       -15.30              83.30    789.70\n",
      "2014-12-31 22:00:00       25.70       -14.80              84.20    792.10\n",
      "2014-12-31 23:00:00       25.70       -14.40              84.00    795.40\n",
      "\n",
      "[34490 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Set the working directory\n",
    "working_dir = \"C:\\\\Year1\\\\\"\n",
    "data_path = os.path.join(working_dir+\"NMVOC\\\\Data\\\\data_Meteo\\\\Meteo_ebas_11_15\\\\*.dat\")\n",
    "save_dir=\"C:\\\\Year1\\\\NMVOC\\\\Data\\\\data_Meteo\\\\\"\n",
    "\n",
    "# Find all .dat files\n",
    "filename = glob.glob(data_path)\n",
    "\n",
    "# List to store processed DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Loop through each file and process it\n",
    "for file in filename:\n",
    "    print(f\"Processing file: {file}\")\n",
    "\n",
    "    try:\n",
    "        # Load data, skipping the first 28 rows (adjust as needed)\n",
    "        df = pd.read_csv(file, sep=r'\\s+', skiprows=28)\n",
    "\n",
    "        # Add a DATETIME column\n",
    "        df[\"DATETIME\"] = pd.to_datetime(df[\"DATE\"].astype(str) + \" \" + df[\"TIME\"].astype(str), errors='coerce')\n",
    "\n",
    "        # Set DATETIME as index\n",
    "        df.index = df[\"DATETIME\"]\n",
    "\n",
    "        # Drop unnecessary columns\n",
    "        df = df.drop([\"DATE\", \"TIME\", \"DATETIME\", \"WD\"], axis=1)\n",
    "\n",
    "        # Remove rows where any column contains -99.9\n",
    "        df = df[~df.eq(-99.9).any(axis=1)]\n",
    "        # Remove rows where any column contains -999.9\n",
    "        df = df[~df.eq(-999.9).any(axis=1)]\n",
    "        \n",
    "        # Drop columns containing \"RAD\" or \"UVB\" in the header\n",
    "        df = df[[col for col in df.columns if \"RAD\" not in col and \"UVB\" not in col]]\n",
    "\n",
    "        # Convert numeric columns to float\n",
    "        df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "        # Resample to hourly means\n",
    "        hourly_df = df.resample(\"h\").mean()\n",
    "\n",
    "        # Rename columns\n",
    "        rename_dict = {\"WS\": \"wind_speed\", \"RH\": \"relative_humidity\", \"AP\": \"pressure\", \"AT\": \"temperature\"}\n",
    "        hourly_df.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "        # Reorder columns\n",
    "        column_order = [\"wind_speed\",\t\"temperature\",\t\"relative_humidity\",\t\"pressure\"]\n",
    "        hourly_df = hourly_df[column_order]\n",
    "\n",
    "        # Append processed DataFrame to list\n",
    "        df_list.append(hourly_df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "# Concatenate all processed DataFrames\n",
    "if df_list:\n",
    "    final_df = pd.concat(df_list)\n",
    "\n",
    "    # Save final concatenated DataFrame\n",
    "    output_file = os.path.join(save_dir, \"processed_met_11_14.csv\")\n",
    "    final_df.to_csv(output_file, index=True)\n",
    "\n",
    "    print(f\"Saved final concatenated data to: {output_file}\")\n",
    "\n",
    "print(\"Processing complete for all .dat files.\")\n",
    "print (final_df)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
